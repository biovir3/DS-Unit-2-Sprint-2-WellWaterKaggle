{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import category_encoders as ce\n",
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import scipy as sp\n",
    "\n",
    "\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./data/train_features.csv')\n",
    "train_y = pd.read_csv('./data/train_labels.csv')\n",
    "\n",
    "test_data = pd.read_csv('./data/test_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.543080808080808\n",
      "0.3842424242424242\n",
      "0.07267676767676767\n"
     ]
    }
   ],
   "source": [
    "#for i in list(train_data.columns):\n",
    "#    print(i)\n",
    "#    print(train_data[i].isnull().sum()\n",
    "train_y['status_group'].value_counts()\n",
    "a = 32259 + 22824 + 4317\n",
    "\n",
    "print(32259/a)\n",
    "print(22824/a)\n",
    "print(4317/a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Features to use \n",
    "features = ['id',\n",
    " 'amount_tsh',\n",
    " 'gps_height',\n",
    "# 'longitude',\n",
    "# 'latitude',\n",
    " 'num_private',\n",
    " 'basin',\n",
    " 'region',\n",
    " 'region_code',\n",
    " 'district_code',\n",
    " 'lga',\n",
    " 'population',\n",
    " 'public_meeting',\n",
    " 'scheme_management',\n",
    " 'permit',\n",
    " 'construction_year',\n",
    " 'extraction_type',\n",
    " 'extraction_type_group',\n",
    " 'extraction_type_class',\n",
    " 'management',\n",
    " 'management_group',\n",
    " 'payment',\n",
    " 'payment_type',\n",
    " 'water_quality',\n",
    " 'quality_group',\n",
    " 'quantity',\n",
    " 'source',\n",
    " 'source_class',\n",
    " 'waterpoint_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [\n",
    " 'basin',\n",
    " 'region',\n",
    " 'lga',\n",
    " 'public_meeting',\n",
    " 'scheme_management',\n",
    " 'permit',\n",
    " 'extraction_type',\n",
    " 'extraction_type_group',\n",
    " 'extraction_type_class',\n",
    " 'management',\n",
    " 'management_group',\n",
    " 'payment',\n",
    " 'payment_type',\n",
    " 'water_quality',\n",
    " 'quality_group',\n",
    " 'quantity',\n",
    " 'source',\n",
    " 'source_class',\n",
    " 'waterpoint_type']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[features]\n",
    "test_data = test_data[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_ord = OrdinalEncoder(cols='status_group')\n",
    "train_y['status'] = ce_ord.fit_transform(train_y)['status_group']\n",
    "#train_y.head(5)\n",
    "#test_y['status'] = ce_ord.fit_transform(test_y)['status_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_ord = OrdinalEncoder(cols=cat_features)\n",
    "#e_ord.fit_transform(train_y)# ['status_group']\n",
    "#train_y.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ce_ord.fit_transform(train_data)\n",
    "test_data = ce_ord.fit_transform(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_data, train_y[['id', 'status']], test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear = linear_model.LogisticRegression()\n",
    "#linear = RandomForestClassifier(n_estimators=1000, max_depth=1125, n_jobs=6)\n",
    "#linear.fit(train_data_First_X,train_y[['id','status']])\n",
    "#linear.score(train_data_First_X,train_y[['id','status']])\n",
    "\n",
    "#linear.fit(X_train,y_train['status'])\n",
    "#print(linear.score(X_train,y_train['status']))\n",
    "\n",
    "#print(linear.score(X_test,y_test['status']))\n",
    "#print('Coeff: ', linear.coef_)\n",
    "#print('Inter: ', linear.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ETC = ExtraTreesClassifier(n_estimators=40,  max_depth=40, \n",
    "#                           min_samples_split=2, min_samples_leaf=2, \n",
    "#                           min_weight_fraction_leaf=0.0, \n",
    "#                           max_leaf_nodes=2500, min_impurity_decrease=0.0, \n",
    "#                           min_impurity_split=None, bootstrap=True, \n",
    "#                           n_jobs=6, random_state=42, verbose=0, warm_start=True)\n",
    "\n",
    "#ETC.fit(X_train,y_train['status'])\n",
    "#print(ETC.score(X_train,y_train['status']))1\n",
    "#print(ETC.score(X_test,y_test['status']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GBC = GradientBoostingClassifier(learning_rate=0.5, n_estimators=5, \n",
    "#                           subsample=1.0, min_samples_split=5, \n",
    "#                           min_samples_leaf=3, min_weight_fraction_leaf=0.000001, \n",
    "#                           max_depth=50, min_impurity_decrease=0.0, \n",
    "#                           min_impurity_split=None, init=None, random_state=42, \n",
    "#                           max_features=None, verbose=10, max_leaf_nodes=None, \n",
    "#                           warm_start=False, validation_fraction=0.1, \n",
    "#                           n_iter_no_change=1, tol=0.00001)\n",
    "#GBC.fit(X_train,y_train['status'])\n",
    "#print(GBC.score(X_train,y_train['status']))\n",
    "#print(GBC.score(X_test,y_test['status']))\n",
    "#print('\\n')\n",
    "#print(jaccard_similarity_score(y_train['status'], GBC.predict(X_train)))\n",
    "#print(jaccard_similarity_score(y_test['status'], GBC.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GBC.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmurphy/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/jmurphy/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:271: UserWarning: The total space of parameters 25 is smaller than n_iter=1500. Running 25 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "/home/jmurphy/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed: 21.3min\n"
     ]
    }
   ],
   "source": [
    "n_searches = 1500\n",
    "params = {\n",
    "# 'learning_rate': [0.1,0.2],#,0.8],\n",
    " 'max_depth': range(3000,4000,200),#[100, 215, 150],#, 1750, 2000],#15,20, 50, 80, ,20,25,30,35,40],\n",
    "# 'min_samples_leaf': [1,2,3,4,5],\n",
    "# 'min_samples_split': [1,2,3,4,5],\n",
    " 'n_estimators': range(2000,3000,200)#,25,30,35,40],\n",
    " }\n",
    "\n",
    "RSCV = RandomizedSearchCV(estimator = RandomForestClassifier(), n_iter = n_searches, n_jobs = 6, verbose = 1, param_distributions= params)\n",
    "\n",
    "RSCV.fit(X_train,y_train['status'])\n",
    "\n",
    "print(RSCV.score(X_train,y_train['status']))\n",
    "print(RSCV.score(X_test,y_test['status']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functional                 8367\n",
      "non functional             5306\n",
      "functional needs repair     685\n",
      "Name: Status_Output, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "test_Output = RSCV.predict(test_data)\n",
    "Submission_Output = pd.DataFrame()\n",
    "Submission_Output['id'] = test_data['id']\n",
    "Submission_Output['Status'] = list(test_Output)\n",
    "\n",
    "Submission_Output['Status_Output'] = Submission_Output['Status'].replace( {1:'functional', 2:'non functional', 3:'functional needs repair'})# ,axis = 0)\n",
    "print(Submission_Output['Status_Output'].value_counts())\n",
    "\n",
    "Subcsv = pd.DataFrame()\n",
    "Subcsv['id'] = Submission_Output['id']\n",
    "Subcsv['status_group'] = Submission_Output['Status_Output']\n",
    "#Subcsv.to_csv('./RSCVsubmit12.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
